[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Parcial Práctico de Series de Tiempo",
    "section": "",
    "text": "Introducción\nEn este parcial práctico se aborda el análisis de series de tiempo utilizando datos relacionados con las acciones del Bitcoin. El objetivo principal es aplicar diversos enfoques de modelado, tanto de Deep Learning como estadísticos, para pronosticar y comprender la dinámica de estas series temporales.\n\n\nModelos Implementados\nEn la parte de Deep Learning, se emplearán redes neuronales recurrentes (RNN), redes neuronales de memoria a largo plazo (LSTM) y perceptrones multicapa (MLP). Por otro lado, en la sección de modelado estadístico, se implementarán modelos de suavización exponencial, Holt-Winters y ARIMA.\nAdemás, se realizará un análisis exploratorio de los datos (EDA) para identificar patrones, tendencias y comportamientos relevantes en las acciones de Bitcoin, proporcionando una base sólida para la posterior implementación de los modelos.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Análisis exploratorio de los datos",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.impute import KNNImputer\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.tsa.stattools import acf, adfuller\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "eda.html#prueba-de-estacionariedad-de-ljung-box",
    "href": "eda.html#prueba-de-estacionariedad-de-ljung-box",
    "title": "Análisis exploratorio de los datos",
    "section": "Prueba de estacionariedad de Ljung-Box",
    "text": "Prueba de estacionariedad de Ljung-Box\n\nresult = acorr_ljungbox(btc_c['Price'], lags=[200, 500, 1000, 2000], return_df=True)\n\nif (result['lb_pvalue'] &lt; 0.05).any():\n    print(\"La serie no es estacionaria (rechazamos la hipótesis nula para algunos lags).\")\nelse:\n    print(\"La serie es estacionaria (no se rechaza la hipótesis nula para los lags evaluados).\")\n\nresult\n\nLa serie no es estacionaria (rechazamos la hipótesis nula para algunos lags).\n\n\n\n\n\n\n\n\n\nlb_stat\nlb_pvalue\n\n\n\n\n200\n6.937886e+05\n0.0\n\n\n500\n1.166338e+06\n0.0\n\n\n1000\n1.598385e+06\n0.0\n\n\n2000\n1.680488e+06\n0.0",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "eda.html#prueba-de-estacionariedad-de-dickey-fuller",
    "href": "eda.html#prueba-de-estacionariedad-de-dickey-fuller",
    "title": "Análisis exploratorio de los datos",
    "section": "Prueba de estacionariedad de Dickey Fuller",
    "text": "Prueba de estacionariedad de Dickey Fuller\n\nresult = adfuller(btc_c['Price'])\n\nprint(f'Estadístico de prueba: {result[0]}')\nprint(f'Valor p: {result[1]}\\n')\n\nif result[1] &lt; 0.05:\n    print(\"La serie es estacionaria (rechazamos la hipótesis nula).\")\nelse:\n    print(\"La serie no es estacionaria (no se rechaza la hipótesis nula).\")\n\nEstadístico de prueba: -2.685797950257253\nValor p: 0.07652825121387376\n\nLa serie no es estacionaria (no se rechaza la hipótesis nula).",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "eda.html#transformaciones-para-obtener-una-serie-estacionaria",
    "href": "eda.html#transformaciones-para-obtener-una-serie-estacionaria",
    "title": "Análisis exploratorio de los datos",
    "section": "Transformaciones para obtener una serie estacionaria",
    "text": "Transformaciones para obtener una serie estacionaria\n\nbtc_d = btc_c.copy()\nbtc_d['Price'] = btc_c['Price'].diff()\n\nbtc_d\n\n\n\n\n\n\n\n\nPrice\nOpen\nHigh\nLow\nVol.\nChange %\nWeek\nMonth\nYear\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n2024-03-24\nNaN\n64036.5\n67587.8\n63812.9\n65590.0\n4.96\n12\n3\n2024\n\n\n2024-03-23\n-3174.1\n63785.6\n65972.4\n63074.9\n35110.0\n0.40\n12\n3\n2024\n\n\n2024-03-22\n-252.3\n65501.5\n66633.3\n62328.3\n72430.0\n-2.62\n12\n3\n2024\n\n\n2024-03-21\n1718.3\n67860.0\n68161.7\n64616.1\n75260.0\n-3.46\n12\n3\n2024\n\n\n2024-03-20\n2350.2\n62046.8\n68029.5\n60850.9\n133530.0\n9.35\n12\n3\n2024\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2010-07-22\n0.0\n0.1\n0.1\n0.1\n2160.0\n0.00\n29\n7\n2010\n\n\n2010-07-21\n0.0\n0.1\n0.1\n0.1\n580.0\n0.00\n29\n7\n2010\n\n\n2010-07-20\n0.0\n0.1\n0.1\n0.1\n260.0\n0.00\n29\n7\n2010\n\n\n2010-07-19\n0.0\n0.1\n0.1\n0.1\n570.0\n0.00\n29\n7\n2010\n\n\n2010-07-18\n0.0\n0.0\n0.1\n0.1\n80.0\n0.00\n28\n7\n2010\n\n\n\n\n4999 rows × 9 columns\n\n\n\n\nresult_diff = adfuller(btc_d['Price'].dropna())\nprint(f'Estadístico de prueba: {result_diff[0]}')\nprint(f'Valor p: {result_diff[1]}\\n')\n\nif result_diff[1] &lt; 0.05:\n    print(\"La serie diferenciada es estacionaria (rechazamos la hipótesis nula).\")\nelse:\n    print(\"La serie diferenciada no es estacionaria (no se rechaza la hipótesis nula).\")\n\nEstadístico de prueba: -10.472194066908118\nValor p: 1.2757808100464155e-18\n\nLa serie diferenciada es estacionaria (rechazamos la hipótesis nula).",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "eda.html#prueba-de-estacionariedad-de-ljung-box-1",
    "href": "eda.html#prueba-de-estacionariedad-de-ljung-box-1",
    "title": "Análisis exploratorio de los datos",
    "section": "Prueba de estacionariedad de Ljung-Box",
    "text": "Prueba de estacionariedad de Ljung-Box\n\nresult = acorr_ljungbox(btc_ma['Price_adj'], lags=[24, 100, 200], return_df=True)\n\nif (result['lb_pvalue'] &lt; 0.05).any():\n    print(\"La serie no es estacionaria (rechazamos la hipótesis nula para algunos lags).\")\nelse:\n    print(\"La serie es estacionaria (no se rechaza la hipótesis nula para los lags evaluados).\")\n\nresult\n\nLa serie no es estacionaria (rechazamos la hipótesis nula para algunos lags).\n\n\n\n\n\n\n\n\n\nlb_stat\nlb_pvalue\n\n\n\n\n24\n417.732848\n1.703098e-73\n\n\n100\n855.651535\n2.501987e-120\n\n\n200\n1256.319601\n2.027382e-152",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "eda.html#prueba-de-estacionariedad-de-dickey-fuller-1",
    "href": "eda.html#prueba-de-estacionariedad-de-dickey-fuller-1",
    "title": "Análisis exploratorio de los datos",
    "section": "Prueba de estacionariedad de Dickey Fuller",
    "text": "Prueba de estacionariedad de Dickey Fuller\n\nresult = adfuller(btc_ma['Price_adj'])\n\nprint(f'Estadístico de prueba: {result[0]}')\nprint(f'Valor p: {result[1]}\\n')\n\nif result[1] &lt; 0.05:\n    print(\"La serie es estacionaria (rechazamos la hipótesis nula).\")\nelse:\n    print(\"La serie no es estacionaria (no se rechaza la hipótesis nula).\")\n\nEstadístico de prueba: -21.518148825437567\nValor p: 0.0\n\nLa serie es estacionaria (rechazamos la hipótesis nula).\n\n\n\nlag_acf = acf(btc_ma['Price_adj'], nlags=100)\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=list(range(len(lag_acf))),\n    y=lag_acf,\n    marker_color='blue'\n))\n\nfig.update_layout(\n    title='Autocorrelación',\n    xaxis_title='Lags',\n    yaxis_title='Autocorrelación',\n    margin={'b': 0, 'r': 30, 'l': 30, 't': 80},\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)',\n    font_color=\"white\",\n    hoverlabel=dict(\n        bgcolor=\"#222\"\n    ),\n    xaxis=dict(gridcolor='#222', tickfont=dict(color='white')),\n    yaxis=dict(gridcolor='#222', tickfont=dict(color='white'))\n)\n\nfig.show()",
    "crumbs": [
      "Análisis exploratorio de datos"
    ]
  },
  {
    "objectID": "deep.html",
    "href": "deep.html",
    "title": "Modelos de deep learning",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport pickle\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense, Input, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers, losses\nfrom scikeras.wrappers import KerasRegressor\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n\nfrom scipy.stats import jarque_bera\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\n\nimport warnings\n\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"scikeras.wrappers\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.layers.core.dense\")",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#series-de-tiempo-del-precio",
    "href": "deep.html#series-de-tiempo-del-precio",
    "title": "Modelos de deep learning",
    "section": "Series de tiempo del precio",
    "text": "Series de tiempo del precio\n\nprice_7 = split_dataset(btc, 7, 'Price')\nprice_14 = split_dataset(btc, 14, 'Price')\nprice_21 = split_dataset(btc, 21, 'Price')\nprice_28 = split_dataset(btc, 28, 'Price')\n\nprice = [price_7, price_14, price_21, price_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {price_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {price_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {price_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {price_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {price_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {price_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {price_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {price_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {price_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {price_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {price_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {price_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {price_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {price_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {price_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {price_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {price_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {price_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {price_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {price_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {price_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {price_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {price_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {price_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#series-de-tiempo-del-retorno-acumulado",
    "href": "deep.html#series-de-tiempo-del-retorno-acumulado",
    "title": "Modelos de deep learning",
    "section": "Series de tiempo del retorno acumulado",
    "text": "Series de tiempo del retorno acumulado\n\nat_7 = split_dataset(btc, 7, 'A_t')\nat_14 = split_dataset(btc, 14, 'A_t')\nat_21 = split_dataset(btc, 21, 'A_t')\nat_28 = split_dataset(btc, 28, 'A_t')\n\nat = [at_7, at_14, at_21, at_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {at_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {at_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {at_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {at_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {at_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {at_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {at_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {at_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {at_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {at_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {at_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {at_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {at_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {at_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {at_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {at_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {at_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {at_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {at_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {at_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {at_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {at_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {at_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {at_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#series-de-tiempo-de-la-volatilidad",
    "href": "deep.html#series-de-tiempo-de-la-volatilidad",
    "title": "Modelos de deep learning",
    "section": "Series de tiempo de la volatilidad",
    "text": "Series de tiempo de la volatilidad\n\nSerie de tiempo de la volatidad para σ = 7\n\nvol_7 = split_dataset(btc, 7, 'σ_7')\nvol_14 = split_dataset(btc, 14, 'σ_7')\nvol_21 = split_dataset(btc, 21, 'σ_7')\nvol_28 = split_dataset(btc, 28, 'σ_7')\n\nvo_7 = [vol_7, vol_14, vol_21, vol_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)\n\n\n\n\nSerie de tiempo de la volatidad para σ = 14\n\nvol_7 = split_dataset(btc, 7, 'σ_14')\nvol_14 = split_dataset(btc, 14, 'σ_14')\nvol_21 = split_dataset(btc, 21, 'σ_14')\nvol_28 = split_dataset(btc, 28, 'σ_14')\n\nvo_14 = [vol_7, vol_14, vol_21, vol_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)\n\n\n\n\nSerie de tiempo de la volatidad para σ = 21\n\nvol_7 = split_dataset(btc, 7, 'σ_21')\nvol_14 = split_dataset(btc, 14, 'σ_21')\nvol_21 = split_dataset(btc, 21, 'σ_21')\nvol_28 = split_dataset(btc, 28, 'σ_21')\n\nvo_21 = [vol_7, vol_14, vol_21, vol_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)\n\n\n\n\nSerie de tiempo de la volatidad para σ = 28\n\nvol_7 = split_dataset(btc, 7, 'σ_7')\nvol_14 = split_dataset(btc, 14, 'σ_7')\nvol_21 = split_dataset(btc, 21, 'σ_7')\nvol_28 = split_dataset(btc, 28, 'σ_7')\n\nvo_28 = [vol_7, vol_14, vol_21, vol_28]\n\nprint('τ = 7')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')\n\nprint('\\nτ = 14')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')\n\nprint('\\nτ = 21')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')\n\nprint('\\nτ = 28')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')\nprint(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')\nprint(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')\nprint(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')\n\nτ = 7\nTamaño del conjunto de entrenamiento τ = 7 en X: (4971, 7)\nTamaño del conjunto de entrenamiento τ = 7 en y: (4971, 1)\nTamaño del conjunto de validación τ = 7 en X: (7, 7)\nTamaño del conjunto de validación τ = 7 en y: (7,)\nTamaño del conjunto de prueba τ = 7 en X: (7, 7)\nTamaño del conjunto de prueba τ = 7 en y: (7,)\n\nτ = 14\nTamaño del conjunto de entrenamiento τ = 14 en X: (4943, 14)\nTamaño del conjunto de entrenamiento τ = 14 en y: (4943, 1)\nTamaño del conjunto de validación τ = 14 en X: (14, 14)\nTamaño del conjunto de validación τ = 14 en y: (14,)\nTamaño del conjunto de prueba τ = 14 en X: (14, 14)\nTamaño del conjunto de prueba τ = 14 en y: (14,)\n\nτ = 21\nTamaño del conjunto de entrenamiento τ = 21 en X: (4915, 21)\nTamaño del conjunto de entrenamiento τ = 21 en y: (4915, 1)\nTamaño del conjunto de validación τ = 21 en X: (21, 21)\nTamaño del conjunto de validación τ = 21 en y: (21,)\nTamaño del conjunto de prueba τ = 21 en X: (21, 21)\nTamaño del conjunto de prueba τ = 21 en y: (21,)\n\nτ = 28\nTamaño del conjunto de entrenamiento τ = 28 en X: (4887, 28)\nTamaño del conjunto de entrenamiento τ = 28 en y: (4887, 1)\nTamaño del conjunto de validación τ = 28 en X: (28, 28)\nTamaño del conjunto de validación τ = 28 en y: (28,)\nTamaño del conjunto de prueba τ = 28 en X: (28, 28)\nTamaño del conjunto de prueba τ = 28 en y: (28,)",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#pliegues-del-precio",
    "href": "deep.html#pliegues-del-precio",
    "title": "Modelos de deep learning",
    "section": "Pliegues del precio",
    "text": "Pliegues del precio\n\ntau_v = [7, 14, 21, 28]\n\nfig_p = plot_folds(price, tau_v, 'Price')\nfig_p.show()",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#pliegues-del-retorno-acumulado",
    "href": "deep.html#pliegues-del-retorno-acumulado",
    "title": "Modelos de deep learning",
    "section": "Pliegues del retorno acumulado",
    "text": "Pliegues del retorno acumulado\n\nfig_p = plot_folds(price, tau_v, 'A_j')\nfig_p.show()",
    "crumbs": [
      "Modelos de deep learning"
    ]
  },
  {
    "objectID": "deep.html#multilayer-perceptron-models-mlp",
    "href": "deep.html#multilayer-perceptron-models-mlp",
    "title": "Modelos de deep learning",
    "section": "Multilayer Perceptron Models (MLP)",
    "text": "Multilayer Perceptron Models (MLP)\n\nPredicciones para el precio\n\nτ = 7\n\ndef build_mlp(dim, learning_rate=0.001, activation='relu'):\n    model = Sequential()\n    model.add(Input(shape=(dim,)))\n    model.add(Dense(64, activation=activation))\n    model.add(Dense(32, activation=activation))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=losses.MeanSquaredError())\n    return model\n\n\ndef get_grid(data, dim, var, tau, w = 1):\n    if var == 'volatilidad':\n        folder_path = f'best_grids/{var}/{var}_{w}_{tau}.pkl'\n    else:\n        folder_path = f'best_grids/{var}/{var}_{tau}.pkl'\n\n    if os.path.exists(folder_path):\n        print(\"Cargando resultados guardados...\")\n        with open(folder_path, 'rb') as file:\n            results = pickle.load(file)\n        return results\n\n    model = KerasRegressor(build_fn = build_mlp, verbose = 0, dim = dim)\n\n    param = {\n        'model__learning_rate': [0.001, 0.01, 0.1, 0.2],\n        'model__activation': ['relu', 'tanh', 'sigmoid'],\n        'epochs': [50, 100, 150]\n    }\n\n    grid = GridSearchCV(\n        estimator = model,\n        param_grid = param,\n        cv = 3,\n        verbose = 2\n    )\n\n    results = grid.fit(data[0], data[1])\n\n    with open(folder_path, 'wb') as file:\n        pickle.dump(results, file)\n\n    return results\n\n\ndim = price[0][0].shape[1]\n\nresults = get_grid(price[0], dim, 'price', 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 50\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9929642587499478\n\n\n\ndef load_models(type_, folder, w, n = 1):\n    if folder == 'volatilidad':\n        folder_path = f'models/{type_}/{folder}/{n}/{w}'\n    else:\n        folder_path = f'models/{type_}/{folder}/{w}'\n\n    models = []\n    for filename in sorted(os.listdir(folder_path)):\n        if filename.endswith('.keras'):\n            models.append(load_model(os.path.join(folder_path, filename)))\n    return models\n\ndef save_models(models, type_, folder, w, n = 1):\n    if folder == 'volatilidad':\n        folder_path = f'models/{type_}/{folder}/{n}/{w}'\n    else:\n        folder_path = f'models/{type_}/{folder}/{w}'\n\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n    \n    for i, model in enumerate(models):\n        model.save(os.path.join(folder_path, f'MLP_{w}_{i}.keras'))\n\ndef build_model(type_, var, dim, neurons, dropouts, activation, learning_rate, w, n = 1):\n    models = load_models(type_, var, w, n)\n    if models:\n        print(f\"Modelos cargados desde la carpeta '{var}'.\")\n        return models\n\n    print(f\"No se encontraron modelos en la carpeta '{var}', construyendo nuevos modelos...\")\n\n    models = []\n\n    for neuron in neurons:\n        for dropout in dropouts:\n            model = Sequential()\n            model.add(Input(shape = (dim, )))\n            model.add(Dense(neuron, activation=activation))\n            model.add(Dense(neuron // 2, activation=activation))\n            model.add(Dense(neuron // 2, activation=activation))\n            model.add(Dropout(dropout))\n            model.add(Dense(1, activation='linear'))\n            model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n            \n            models.append(model)\n\n            print(f'Modelo con {(neuron, neuron // 2, neuron // 2, 1)} neuronas y dropout {dropout}:')\n            model.summary()\n\n    save_models(models, type_, var, w, n)\n    return models\n\n\nneurons = [32, 64, 128]\ndropouts = [0.2, 0.4, 0.6, 0.8]\n\nmodels = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 7)\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'price'.\n\n\n\ndef best_model(models, X_val, y_val):\n    results = []\n\n    for i, model in enumerate(models):\n        pred = model.predict(X_val)\n\n        pred = pred.ravel()\n        y_val = y_val.ravel()\n\n        mape = mean_absolute_percentage_error(y_val, pred)\n        mae = mean_absolute_error(y_val, pred)\n        mse = mean_squared_error(y_val, pred)\n        rmse = np.sqrt(mse)\n        r2 = r2_score(y_val, pred)\n\n        #ljungbox = acorr_ljungbox(pred - y_val, lags = [10], return_df = True)['lb_pvalue'].iloc[0]\n        jb_stat, jb_p = jarque_bera(pred - y_val)\n\n        print(f'Modelo {i}: MSE = {mse:.4f}')\n\n        results.append({\n            \"Model Name\": f'MLP_Price_{i}',\n            \"MAPE\": mape,\n            \"MAE\": mae,\n            \"RMSE\": rmse,\n            \"MSE\": mse,\n            \"R2\": r2,\n            #\"Ljung-Box P-Value\": ljungbox,\n            \"Jarque-Bera P-Value\": jb_p\n        })\n\n    results = pd.DataFrame(results)\n    return results\n\n\nmlp_p7_metrics = best_model(models, price[0][2], price[0][3])\n\nmlp_p7_metrics\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step\nModelo 0: MSE = 0.0087\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 1: MSE = 0.0053\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0102\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0171\nWARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x30c6b1700&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 4: MSE = 0.0130\nWARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x30c6b1d30&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0211\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 0.0103\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 7: MSE = 0.0135\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 8: MSE = 0.0118\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 9: MSE = 0.0015\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 10: MSE = 0.0074\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 11: MSE = 0.0246\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.933592\n0.093359\n0.093359\n0.008716\n-4.525579e+31\n0.55747\n\n\n1\nMLP_Price_1\n0.725742\n0.072574\n0.072574\n0.005267\n-2.734788e+31\n0.55747\n\n\n2\nMLP_Price_2\n1.008198\n0.100820\n0.100820\n0.010165\n-5.277783e+31\n0.55747\n\n\n3\nMLP_Price_3\n1.306148\n0.130615\n0.130615\n0.017060\n-8.858173e+31\nNaN\n\n\n4\nMLP_Price_4\n1.139195\n0.113920\n0.113920\n0.012978\n-6.738385e+31\n0.55747\n\n\n5\nMLP_Price_5\n1.454286\n0.145429\n0.145429\n0.021149\n-1.098144e+32\n0.55747\n\n\n6\nMLP_Price_6\n1.012448\n0.101245\n0.101245\n0.010251\n-5.322367e+31\nNaN\n\n\n7\nMLP_Price_7\n1.163491\n0.116349\n0.116349\n0.013537\n-7.028867e+31\nNaN\n\n\n8\nMLP_Price_8\n1.085518\n0.108552\n0.108552\n0.011783\n-6.118338e+31\nNaN\n\n\n9\nMLP_Price_9\n0.390892\n0.039089\n0.039089\n0.001528\n-7.933669e+30\nNaN\n\n\n10\nMLP_Price_10\n0.858189\n0.085819\n0.085819\n0.007365\n-3.824063e+31\nNaN\n\n\n11\nMLP_Price_11\n1.569040\n0.156904\n0.156904\n0.024619\n-1.278285e+32\n0.55747\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = price[1][0].shape[1]\n\nresults = get_grid(price[1], dim, 'price', 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9923356886891406\n\n\n\nmodels = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 14)\n\nmlp_p14_metrics = best_model(models, price[1][2], price[1][3])\nmlp_p14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'price'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\nModelo 0: MSE = 0.0119\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0219\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 2: MSE = 0.0118\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 0.0146\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0254\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0116\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 6: MSE = 0.0107\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 7: MSE = 0.0159\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 8: MSE = 0.0129\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0043\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\nModelo 10: MSE = 0.0153\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 11: MSE = 0.0122\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n1.088821\n0.108882\n0.108882\n0.011855\n-6.155626e+31\n0.245879\n\n\n1\nMLP_Price_1\n1.480355\n0.148035\n0.148035\n0.021914\n-1.137866e+32\n0.245879\n\n\n2\nMLP_Price_2\n1.085182\n0.108518\n0.108518\n0.011776\n-6.114548e+31\n0.245879\n\n\n3\nMLP_Price_3\n1.210023\n0.121002\n0.121002\n0.014642\n-7.602329e+31\n0.245879\n\n\n4\nMLP_Price_4\n1.593198\n0.159320\n0.159320\n0.025383\n-1.317951e+32\n0.245879\n\n\n5\nMLP_Price_5\n1.077287\n0.107729\n0.107729\n0.011605\n-6.025910e+31\nNaN\n\n\n6\nMLP_Price_6\n1.032645\n0.103265\n0.103265\n0.010664\n-5.536839e+31\n0.245879\n\n\n7\nMLP_Price_7\n1.262066\n0.126207\n0.126207\n0.015928\n-8.270341e+31\n0.245879\n\n\n8\nMLP_Price_8\n1.136970\n0.113697\n0.113697\n0.012927\n-6.712084e+31\nNaN\n\n\n9\nMLP_Price_9\n0.654840\n0.065484\n0.065484\n0.004288\n-2.226534e+31\nNaN\n\n\n10\nMLP_Price_10\n1.237239\n0.123724\n0.123724\n0.015308\n-7.948164e+31\nNaN\n\n\n11\nMLP_Price_11\n1.103586\n0.110359\n0.110359\n0.012179\n-6.323704e+31\n0.245879\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = price[2][0].shape[1]\n\nresults = get_grid(price[2], dim, 'price', 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.992061931285642\n\n\n\nmodels = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 21)\n\nmlp_p21_metrics = best_model(models, price[2][2], price[2][3])\nmlp_p21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'price'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 0: MSE = 0.0011\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0104\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0074\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0099\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0118\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0441\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 6: MSE = 0.0076\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0067\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 8: MSE = 0.0081\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\nModelo 9: MSE = 0.0089\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 10: MSE = 0.0041\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0267\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.324668\n0.032467\n0.032467\n0.001054\n-5.473179e+30\n0.011652\n\n\n1\nMLP_Price_1\n1.021305\n0.102130\n0.102130\n0.010431\n-5.415893e+31\n0.011652\n\n\n2\nMLP_Price_2\n0.858484\n0.085848\n0.085848\n0.007370\n-3.826697e+31\nNaN\n\n\n3\nMLP_Price_3\n0.994687\n0.099469\n0.099469\n0.009894\n-5.137266e+31\n0.011652\n\n\n4\nMLP_Price_4\n1.088038\n0.108804\n0.108804\n0.011838\n-6.146784e+31\n0.011652\n\n\n5\nMLP_Price_5\n2.099725\n0.209973\n0.209973\n0.044088\n-2.289203e+32\nNaN\n\n\n6\nMLP_Price_6\n0.871561\n0.087156\n0.087156\n0.007596\n-3.944169e+31\nNaN\n\n\n7\nMLP_Price_7\n0.819830\n0.081983\n0.081983\n0.006721\n-3.489850e+31\nNaN\n\n\n8\nMLP_Price_8\n0.902006\n0.090201\n0.090201\n0.008136\n-4.224529e+31\nNaN\n\n\n9\nMLP_Price_9\n0.942669\n0.094267\n0.094267\n0.008886\n-4.614005e+31\nNaN\n\n\n10\nMLP_Price_10\n0.641203\n0.064120\n0.064120\n0.004111\n-2.134768e+31\nNaN\n\n\n11\nMLP_Price_11\n1.633952\n0.163395\n0.163395\n0.026698\n-1.386239e+32\nNaN\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = price[3][0].shape[1]\n\nresults = get_grid(price[3], dim, 'price', 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 50\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.9915164107311906\n\n\n\nmodels = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 28)\n\nmlp_p28_metrics = best_model(models, price[3][2], price[3][3])\nmlp_p28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'price'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 0: MSE = 0.0003\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0085\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0105\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 3: MSE = 0.0172\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0090\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0006\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 6: MSE = 0.0088\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 7: MSE = 0.0168\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 8: MSE = 0.0050\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 9: MSE = 0.0087\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 10: MSE = 0.0273\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\nModelo 11: MSE = 0.0209\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.171046\n0.017105\n0.018523\n0.000343\n-1.781498e+30\n4.947980e-03\n\n\n1\nMLP_Price_1\n0.919785\n0.091978\n0.092095\n0.008481\n-4.403843e+31\n7.044676e-23\n\n\n2\nMLP_Price_2\n1.021332\n0.102133\n0.102334\n0.010472\n-5.437525e+31\n1.268079e-02\n\n\n3\nMLP_Price_3\n1.305967\n0.130597\n0.131146\n0.017199\n-8.930358e+31\n1.218378e-01\n\n\n4\nMLP_Price_4\n0.950463\n0.095046\n0.095080\n0.009040\n-4.693975e+31\n8.858452e-07\n\n\n5\nMLP_Price_5\n0.230914\n0.023091\n0.025364\n0.000643\n-3.340493e+30\n8.672279e-02\n\n\n6\nMLP_Price_6\n0.933272\n0.093327\n0.093712\n0.008782\n-4.559847e+31\n6.673026e-02\n\n\n7\nMLP_Price_7\n1.292144\n0.129214\n0.129778\n0.016842\n-8.745025e+31\n1.005144e-03\n\n\n8\nMLP_Price_8\n0.701524\n0.070152\n0.070636\n0.004989\n-2.590696e+31\n2.241195e-01\n\n\n9\nMLP_Price_9\n0.932640\n0.093264\n0.093422\n0.008728\n-4.531647e+31\n1.477324e-06\n\n\n10\nMLP_Price_10\n1.650198\n0.165020\n0.165223\n0.027298\n-1.417418e+32\n3.693883e-18\n\n\n11\nMLP_Price_11\n1.443498\n0.144350\n0.144478\n0.020874\n-1.083842e+32\n9.277897e-17\n\n\n\n\n\n\n\n\n\n\nPredicciones para el retorno acumulado\n\nτ = 7\n\ndim = at[0][0].shape[1]\n\nresults = get_grid(at[0], dim, 'retorno', 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.9953678427084359\n\n\n\nmodels = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 7)\n\nmlp_at7_metrics = best_model(models, at[0][2], at[0][3])\nmlp_at7_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'retorno'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 0: MSE = 13.5456\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 130ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step\nModelo 1: MSE = 6.5067\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 16.8533\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 31.8977\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 32.0769\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 28.4867\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 13.2960\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 7: MSE = 22.6537\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 8: MSE = 9.9795\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 9: MSE = 13.0616\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 10: MSE = 5.4229\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 19.5227\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.851365\n3.680431\n3.680431\n13.545571\n0.0\n0.55747\n\n\n1\nMLP_Price_1\n0.590060\n2.550815\n2.550815\n6.506657\n0.0\n0.55747\n\n\n2\nMLP_Price_2\n0.949641\n4.105279\n4.105279\n16.853318\n0.0\n0.55747\n\n\n3\nMLP_Price_3\n1.306462\n5.647805\n5.647805\n31.897697\n0.0\nNaN\n\n\n4\nMLP_Price_4\n1.310126\n5.663645\n5.663645\n32.076874\n0.0\nNaN\n\n\n5\nMLP_Price_5\n1.234634\n5.337297\n5.337297\n28.486740\n0.0\n0.55747\n\n\n6\nMLP_Price_6\n0.843485\n3.646367\n3.646367\n13.295995\n0.0\nNaN\n\n\n7\nMLP_Price_7\n1.100998\n4.759590\n4.759590\n22.653696\n0.0\nNaN\n\n\n8\nMLP_Price_8\n0.730754\n3.159033\n3.159033\n9.979490\n0.0\nNaN\n\n\n9\nMLP_Price_9\n0.836017\n3.614082\n3.614082\n13.061586\n0.0\nNaN\n\n\n10\nMLP_Price_10\n0.538684\n2.328720\n2.328720\n5.422937\n0.0\nNaN\n\n\n11\nMLP_Price_11\n1.022086\n4.418454\n4.418454\n19.522739\n0.0\n0.55747\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = at[1][0].shape[1]\n\nresults = get_grid(at[1], dim, 'retorno', 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9947286045222513\n\n\n\nmodels = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 14)\n\nmlp_at14_metrics = best_model(models, at[1][2], at[1][3])\nmlp_at14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'retorno'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 18.0576\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 1: MSE = 21.3061\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 2: MSE = 18.5075\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 21.6683\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 4: MSE = 18.0936\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 5: MSE = 21.4362\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 4.8328\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 19.3612\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 8: MSE = 24.7572\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 9: MSE = 13.9393\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 25.1080\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 23.0428\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.982985\n4.249425\n4.249425\n18.057611\n-2.289074e+31\n0.245879\n\n\n1\nMLP_Price_1\n1.067749\n4.615857\n4.615857\n21.306138\n-2.700874e+31\n0.245879\n\n\n2\nMLP_Price_2\n0.995156\n4.302037\n4.302037\n18.507526\n-2.346108e+31\nNaN\n\n\n3\nMLP_Price_3\n1.076787\n4.654926\n4.654926\n21.668332\n-2.746787e+31\n0.245879\n\n\n4\nMLP_Price_4\n0.983966\n4.253663\n4.253663\n18.093648\n-2.293642e+31\nNaN\n\n\n5\nMLP_Price_5\n1.071004\n4.629929\n4.629929\n21.436242\n-2.717366e+31\nNaN\n\n\n6\nMLP_Price_6\n0.508532\n2.198373\n2.198373\n4.832846\n-6.126360e+30\nNaN\n\n\n7\nMLP_Price_7\n1.017849\n4.400140\n4.400140\n19.361229\n-2.454327e+31\nNaN\n\n\n8\nMLP_Price_8\n1.150979\n4.975658\n4.975658\n24.757176\n-3.138345e+31\nNaN\n\n\n9\nMLP_Price_9\n0.863649\n3.733536\n3.733536\n13.939291\n-1.767015e+31\nNaN\n\n\n10\nMLP_Price_10\n1.159105\n5.010787\n5.010787\n25.107990\n-3.182816e+31\n0.245879\n\n\n11\nMLP_Price_11\n1.110414\n4.800294\n4.800294\n23.042820\n-2.921025e+31\nNaN\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = at[2][0].shape[1]\n\nresults = get_grid(at[2], dim, 'retorno', 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: sigmoid\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9944296065331537\n\n\n\nmodels = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 21)\n\nmlp_at21_metrics = best_model(models, at[2][2], at[2][3])\nmlp_at21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'retorno'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 15.9112\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 1: MSE = 18.6403\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 16.3590\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 14.0434\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 4: MSE = 18.7071\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 19.2759\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 8.8351\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 7: MSE = 15.1769\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 8: MSE = 12.4313\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 9: MSE = 16.4611\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 10: MSE = 18.3412\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\nModelo 11: MSE = 17.6120\n\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2116: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/scipy/stats/_stats_py.py:2117: RuntimeWarning:\n\nPrecision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.922717\n3.988885\n3.988885\n15.911201\n-2.016984e+31\nNaN\n\n\n1\nMLP_Price_1\n0.998718\n4.317438\n4.317438\n18.640267\n-2.362935e+31\nNaN\n\n\n2\nMLP_Price_2\n0.935610\n4.044621\n4.044621\n16.358958\n-2.073744e+31\n0.011652\n\n\n3\nMLP_Price_3\n0.866869\n3.747456\n3.747456\n14.043430\n-1.780216e+31\nNaN\n\n\n4\nMLP_Price_4\n1.000508\n4.325176\n4.325176\n18.707149\n-2.371413e+31\nNaN\n\n\n5\nMLP_Price_5\n1.015603\n4.390428\n4.390428\n19.275856\n-2.443505e+31\n0.011652\n\n\n6\nMLP_Price_6\n0.687578\n2.972386\n2.972386\n8.835076\n-1.119979e+31\nNaN\n\n\n7\nMLP_Price_7\n0.901173\n3.895749\n3.895749\n15.176864\n-1.923896e+31\nNaN\n\n\n8\nMLP_Price_8\n0.815598\n3.525812\n3.525812\n12.431349\n-1.575861e+31\nNaN\n\n\n9\nMLP_Price_9\n0.938525\n4.057223\n4.057223\n16.461059\n-2.086687e+31\nNaN\n\n\n10\nMLP_Price_10\n0.990675\n4.282668\n4.282668\n18.341241\n-2.325029e+31\nNaN\n\n\n11\nMLP_Price_11\n0.970782\n4.196668\n4.196668\n17.612022\n-2.232589e+31\n0.011652\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = at[3][0].shape[1]\n\nresults = get_grid(at[3], dim, 'retorno', 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 50\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9926096353221231\n\n\n\nmodels = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 28)\n\nmlp_at28_metrics = best_model(models, at[3][2], at[3][3])\nmlp_at28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'retorno'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 21.2353\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 1: MSE = 28.0062\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 2: MSE = 13.2884\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 20.3033\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 4: MSE = 22.2990\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 5: MSE = 19.4056\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 6: MSE = 11.5393\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 7: MSE = 17.3125\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 8: MSE = 19.5027\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 9: MSE = 27.7216\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 10: MSE = 16.9307\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 8.9896\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n1.065973\n4.608177\n4.608178\n21.235300\n-2.691894e+31\n1.492363e-01\n\n\n1\nMLP_Price_1\n1.224176\n5.292086\n5.292086\n28.006174\n-3.550204e+31\n1.041470e-01\n\n\n2\nMLP_Price_2\n0.843245\n3.645330\n3.645330\n13.288431\n-1.684509e+31\n2.453968e-11\n\n\n3\nMLP_Price_3\n1.042319\n4.505923\n4.505923\n20.303339\n-2.573754e+31\n6.852999e-02\n\n\n4\nMLP_Price_4\n1.092344\n4.722177\n4.722178\n22.298961\n-2.826729e+31\n8.630661e-02\n\n\n5\nMLP_Price_5\n1.019015\n4.405180\n4.405181\n19.405622\n-2.459955e+31\n2.404680e-04\n\n\n6\nMLP_Price_6\n0.785789\n3.396948\n3.396948\n11.539258\n-1.462775e+31\n7.977298e-02\n\n\n7\nMLP_Price_7\n0.962491\n4.160828\n4.160828\n17.312489\n-2.194619e+31\n2.762365e-03\n\n\n8\nMLP_Price_8\n1.021561\n4.416188\n4.416188\n19.502714\n-2.472263e+31\n2.311245e-02\n\n\n9\nMLP_Price_9\n1.217942\n5.265135\n5.265135\n27.721643\n-3.514136e+31\n4.282240e-02\n\n\n10\nMLP_Price_10\n0.951819\n4.114693\n4.114694\n16.930703\n-2.146222e+31\n7.021213e-02\n\n\n11\nMLP_Price_11\n0.693565\n2.998265\n2.998265\n8.989592\n-1.139566e+31\n1.668459e-10\n\n\n\n\n\n\n\n\n\n\nPredicciones para la volatilidad\n\nVolatilidad con ventana σ = 7\n\nτ = 7\n\ndim = vo_7[0][0].shape[1]\n\nresults = get_grid(vo_7[0], dim, 'volatilidad', 7, 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.8458686359787372\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 7)\n\nmlp_vol7_7_metrics = best_model(models, vo_7[0][2], vo_7[0][3])\nmlp_vol7_7_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = vo_7[1][0].shape[1]\n\nresults = get_grid(vo_7[1], dim, 'volatilidad', 14, 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.8851995559100326\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 7)\n\nmlp_vol7_14_metrics = best_model(models, vo_7[1][2], vo_7[1][3])\nmlp_vol7_14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = vo_7[2][0].shape[1]\n\nresults = get_grid(vo_7[2], dim, 'volatilidad', 21, 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.8838780194852301\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 7)\n\nmlp_vol7_21_metrics = best_model(models, vo_7[2][2], vo_7[2][3])\nmlp_vol7_21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = vo_7[3][0].shape[1]\n\nresults = get_grid(vo_7[3], dim, 'volatilidad', 28, 7)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.8735585364167684\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 7)\n\nmlp_vol7_28_metrics = best_model(models, vo_7[3][2], vo_7[3][3])\nmlp_vol7_28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step\nModelo 0: MSE = 0.0451\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 1: MSE = 0.0034\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0024\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 3: MSE = 0.0102\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 4: MSE = 0.0114\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 5: MSE = 0.0085\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 6: MSE = 0.0019\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0038\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 8: MSE = 0.0072\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 9: MSE = 0.0286\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 10: MSE = 0.0759\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 11: MSE = 0.0087\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n7.162994e+14\n0.159050\n0.212475\n0.045146\n0.0\n0.499207\n\n\n1\nMLP_Price_1\n1.794322e+14\n0.039842\n0.057953\n0.003359\n0.0\n0.989639\n\n\n2\nMLP_Price_2\n1.590308e+14\n0.035312\n0.049172\n0.002418\n0.0\n0.561823\n\n\n3\nMLP_Price_3\n2.797398e+14\n0.062115\n0.100935\n0.010188\n0.0\n0.075613\n\n\n4\nMLP_Price_4\n3.061127e+14\n0.067971\n0.106804\n0.011407\n0.0\n0.185153\n\n\n5\nMLP_Price_5\n2.837046e+14\n0.062995\n0.092310\n0.008521\n0.0\n0.336134\n\n\n6\nMLP_Price_6\n1.287562e+14\n0.028590\n0.043272\n0.001872\n0.0\n0.195448\n\n\n7\nMLP_Price_7\n1.842945e+14\n0.040922\n0.061281\n0.003755\n0.0\n0.485559\n\n\n8\nMLP_Price_8\n2.483087e+14\n0.055136\n0.084717\n0.007177\n0.0\n0.217519\n\n\n9\nMLP_Price_9\n5.017698e+14\n0.111415\n0.169115\n0.028600\n0.0\n0.216930\n\n\n10\nMLP_Price_10\n8.429797e+14\n0.187179\n0.275426\n0.075859\n0.0\n0.200165\n\n\n11\nMLP_Price_11\n2.745355e+14\n0.060959\n0.093203\n0.008687\n0.0\n0.163997\n\n\n\n\n\n\n\n\n\n\nVolatilidad con ventana σ = 14\n\nτ = 7\n\ndim = vo_14[0][0].shape[1]\n\nresults = get_grid(vo_14[0], dim, 'volatilidad', 7, 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9347361334808304\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 14)\n\nmlp_vol14_7_metrics = best_model(models, vo_14[0][2], vo_14[0][3])\nmlp_vol14_7_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = vo_14[1][0].shape[1]\n\nresults = get_grid(vo_14[1], dim, 'volatilidad', 14, 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9331265147277118\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 14)\n\nmlp_vol14_14_metrics = best_model(models, vo_14[1][2], vo_14[1][3])\nmlp_vol14_14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = vo_14[2][0].shape[1]\n\nresults = get_grid(vo_14[2], dim, 'volatilidad', 21, 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9518923980994929\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 14)\n\nmlp_vol14_21_metrics = best_model(models, vo_14[2][2], vo_14[2][3])\nmlp_vol14_21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = vo_14[3][0].shape[1]\n\nresults = get_grid(vo_14[3], dim, 'volatilidad', 28, 14)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 150\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.9487999966795\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 14)\n\nmlp_vol14_28_metrics = best_model(models, vo_14[3][2], vo_14[3][3])\nmlp_vol14_28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 0: MSE = 0.0065\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 1: MSE = 0.0091\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0032\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0061\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.1288\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 5: MSE = 0.0072\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 0.0026\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 7: MSE = 0.0012\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 8: MSE = 0.0037\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 9: MSE = 0.0092\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step\nModelo 10: MSE = 0.0022\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 11: MSE = 0.0032\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n2.896786e+14\n0.064322\n0.080682\n0.006510\n0.0\n0.610347\n\n\n1\nMLP_Price_1\n3.629986e+14\n0.080602\n0.095384\n0.009098\n0.0\n0.378620\n\n\n2\nMLP_Price_2\n2.233342e+14\n0.049590\n0.056374\n0.003178\n0.0\n0.370159\n\n\n3\nMLP_Price_3\n2.897920e+14\n0.064347\n0.077794\n0.006052\n0.0\n0.579961\n\n\n4\nMLP_Price_4\n1.360298e+15\n0.302047\n0.358896\n0.128806\n0.0\n0.200652\n\n\n5\nMLP_Price_5\n2.998405e+14\n0.066578\n0.085084\n0.007239\n0.0\n0.563968\n\n\n6\nMLP_Price_6\n1.894117e+14\n0.042058\n0.051380\n0.002640\n0.0\n0.701491\n\n\n7\nMLP_Price_7\n1.301509e+14\n0.028899\n0.035027\n0.001227\n0.0\n0.621220\n\n\n8\nMLP_Price_8\n2.004332e+14\n0.044505\n0.060973\n0.003718\n0.0\n0.255349\n\n\n9\nMLP_Price_9\n3.788565e+14\n0.084123\n0.096175\n0.009250\n0.0\n0.387125\n\n\n10\nMLP_Price_10\n1.767774e+14\n0.039252\n0.047189\n0.002227\n0.0\n0.617283\n\n\n11\nMLP_Price_11\n2.147773e+14\n0.047690\n0.056558\n0.003199\n0.0\n0.483371\n\n\n\n\n\n\n\n\n\n\nVolatilidad con ventana σ = 21\n\nτ = 7\n\ndim = vo_21[0][0].shape[1]\n\nresults = get_grid(vo_21[0], dim, 'volatilidad', 7, 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.958933652212678\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 21)\n\nmlp_vol21_7_metrics = best_model(models, vo_21[0][2], vo_21[0][3])\nmlp_vol21_7_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = vo_21[1][0].shape[1]\n\nresults = get_grid(vo_21[1], dim, 'volatilidad', 14, 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.9590606369714157\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 21)\n\nmlp_vol21_14_metrics = best_model(models, vo_21[1][2], vo_21[1][3])\nmlp_vol21_14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = vo_21[2][0].shape[1]\n\nresults = get_grid(vo_21[2], dim, 'volatilidad', 21, 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 50\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9588696357579239\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 21)\n\nmlp_vol21_21_metrics = best_model(models, vo_21[2][2], vo_21[2][3])\nmlp_vol21_21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 0: MSE = 0.4251\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 1: MSE = 0.1071\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step\nModelo 2: MSE = 1.7569\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 3: MSE = 0.2702\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step\nModelo 4: MSE = 0.0051\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step\nModelo 5: MSE = 0.0045\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step\nModelo 6: MSE = 0.9637\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 7: MSE = 0.4901\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step\nModelo 8: MSE = 1.6636\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 9: MSE = 0.5232\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 0.0606\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 11: MSE = 0.1050\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n2.936339e+15\n0.651998\n0.651998\n0.425102\n0.0\n2.045677e-05\n\n\n1\nMLP_Price_1\n1.473618e+15\n0.327209\n0.327209\n0.107066\n0.0\n3.758186e-03\n\n\n2\nMLP_Price_2\n5.969479e+15\n1.325491\n1.325491\n1.756925\n0.0\n4.163555e-04\n\n\n3\nMLP_Price_3\n2.340928e+15\n0.519790\n0.519790\n0.270182\n0.0\n2.181144e-02\n\n\n4\nMLP_Price_4\n3.220082e+14\n0.071500\n0.071500\n0.005112\n0.0\n3.754697e-02\n\n\n5\nMLP_Price_5\n3.028158e+14\n0.067239\n0.067239\n0.004521\n0.0\n1.270918e-29\n\n\n6\nMLP_Price_6\n4.421050e+15\n0.981670\n0.981670\n0.963676\n0.0\n7.620207e-10\n\n\n7\nMLP_Price_7\n3.152691e+15\n0.700038\n0.700038\n0.490053\n0.0\n3.278896e-05\n\n\n8\nMLP_Price_8\n5.808749e+15\n1.289801\n1.289801\n1.663587\n0.0\n3.886970e-07\n\n\n9\nMLP_Price_9\n3.257432e+15\n0.723295\n0.723295\n0.523156\n0.0\n3.281390e-03\n\n\n10\nMLP_Price_10\n1.108672e+15\n0.246175\n0.246175\n0.060602\n0.0\n5.361850e-26\n\n\n11\nMLP_Price_11\n1.459581e+15\n0.324092\n0.324092\n0.105036\n0.0\n6.528045e-05\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = vo_21[3][0].shape[1]\n\nresults = get_grid(vo_21[3], dim, 'volatilidad', 28, 21)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.9707786364616338\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 21)\n\nmlp_vol21_28_metrics = best_model(models, vo_21[3][2], vo_21[3][3])\nmlp_vol21_28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\nModelo 0: MSE = 0.0085\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step\nModelo 1: MSE = 0.0024\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 2: MSE = 0.0030\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 0.0033\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0019\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 5: MSE = 0.0122\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 6: MSE = 0.0051\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 7: MSE = 0.0075\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 8: MSE = 0.0070\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 9: MSE = 0.0094\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 0.0020\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0014\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n1.564857e+14\n0.069459\n0.092173\n0.008496\n-3.865243\n0.008532\n\n\n1\nMLP_Price_1\n1.839391e+14\n0.043247\n0.048635\n0.002365\n-0.354568\n0.378879\n\n\n2\nMLP_Price_2\n5.063465e+13\n0.033515\n0.054505\n0.002971\n-0.701261\n0.002028\n\n\n3\nMLP_Price_3\n8.273847e+13\n0.040933\n0.057785\n0.003339\n-0.912148\n0.004419\n\n\n4\nMLP_Price_4\n2.666782e+13\n0.023944\n0.043379\n0.001882\n-0.077605\n0.002372\n\n\n5\nMLP_Price_5\n1.488474e+14\n0.074913\n0.110356\n0.012178\n-5.974118\n0.111068\n\n\n6\nMLP_Price_6\n9.634084e+13\n0.049596\n0.071310\n0.005085\n-1.912015\n0.002437\n\n\n7\nMLP_Price_7\n3.345719e+14\n0.077327\n0.086720\n0.007520\n-3.306620\n0.603024\n\n\n8\nMLP_Price_8\n1.294174e+14\n0.061066\n0.083875\n0.007035\n-3.028680\n0.005031\n\n\n9\nMLP_Price_9\n1.295304e+14\n0.065887\n0.097198\n0.009448\n-4.410232\n0.046383\n\n\n10\nMLP_Price_10\n1.456937e+14\n0.038858\n0.044239\n0.001957\n-0.120765\n0.297847\n\n\n11\nMLP_Price_11\n1.097412e+14\n0.033493\n0.036828\n0.001356\n0.223314\n0.044301\n\n\n\n\n\n\n\n\n\n\nVolatilidad con ventana σ = 28\n\nτ = 7\n\ndim = vo_28[0][0].shape[1]\n\nresults = get_grid(vo_28[0], dim, 'volatilidad', 7, 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: tanh\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.8510466752155451\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 28)\n\nmlp_vol28_7_metrics = best_model(models, vo_28[0][2], vo_28[0][3])\nmlp_vol28_7_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 14\n\ndim = vo_28[1][0].shape[1]\n\nresults = get_grid(vo_28[1], dim, 'volatilidad', 14, 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.8812891588138462\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 28)\n\nmlp_vol28_14_metrics = best_model(models, vo_28[1][2], vo_28[1][3])\nmlp_vol28_14_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 21\n\ndim = vo_28[2][0].shape[1]\n\nresults = get_grid(vo_28[2], dim, 'volatilidad', 21, 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.001\nMejor Puntuación: 0.8813218143824045\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 28)\n\nmlp_vol28_21_metrics = best_model(models, vo_28[2][2], vo_28[2][3])\nmlp_vol28_21_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 0: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 1: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 2: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 3: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 4: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 5: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 6: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 8: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 9: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step\nModelo 10: MSE = 0.0000\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 11: MSE = 0.0000\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n1\nMLP_Price_1\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n2\nMLP_Price_2\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n3\nMLP_Price_3\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n4\nMLP_Price_4\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n5\nMLP_Price_5\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n6\nMLP_Price_6\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n7\nMLP_Price_7\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n8\nMLP_Price_8\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n9\nMLP_Price_9\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n10\nMLP_Price_10\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n11\nMLP_Price_11\n0.0\n0.0\n0.0\n0.0\n1.0\nNaN\n\n\n\n\n\n\n\n\n\nτ = 28\n\ndim = vo_28[3][0].shape[1]\n\nresults = get_grid(vo_28[3], dim, 'volatilidad', 28, 28)\n\nbest_params = results.best_params_\nbest_activation = results.best_params_['model__activation']\nbest_epochs = results.best_params_['epochs']\nbest_mu = results.best_params_['model__learning_rate']\nbest_score = results.best_score_\n\nprint(f\"Mejor función de activación: {best_activation}\")\nprint(f\"Mejor número de epocas: {best_epochs}\")\nprint(f\"Mejor Longitud de paso μ (Learning Rate): {best_mu}\")\nprint(f\"Mejor Puntuación: {best_score}\")\n\nCargando resultados guardados...\nMejor función de activación: relu\nMejor número de epocas: 100\nMejor Longitud de paso μ (Learning Rate): 0.01\nMejor Puntuación: 0.8743495907125691\n\n\n\nmodels = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 28)\n\nmlp_vol28_28_metrics = best_model(models, vo_28[3][2], vo_28[3][3])\nmlp_vol28_28_metrics\n\n/opt/anaconda3/envs/pt_ts/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n\nSkipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n\n\n\nModelos cargados desde la carpeta 'volatilidad'.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 0: MSE = 0.0021\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 1: MSE = 0.0005\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 2: MSE = 0.0006\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 3: MSE = 0.0012\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 4: MSE = 0.0017\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 5: MSE = 0.0017\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 6: MSE = 0.0007\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\nModelo 7: MSE = 0.0004\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 8: MSE = 0.0003\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\nModelo 9: MSE = 0.0057\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\nModelo 10: MSE = 0.0027\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\nModelo 11: MSE = 0.0017\n\n\n\n\n\n\n\n\n\nModel Name\nMAPE\nMAE\nRMSE\nMSE\nR2\nJarque-Bera P-Value\n\n\n\n\n0\nMLP_Price_0\n1.473632e+14\n0.032721\n0.045414\n0.002062\n0.0\n0.284712\n\n\n1\nMLP_Price_1\n6.236684e+13\n0.013848\n0.021517\n0.000463\n0.0\n0.103652\n\n\n2\nMLP_Price_2\n7.109195e+13\n0.015786\n0.023828\n0.000568\n0.0\n0.233961\n\n\n3\nMLP_Price_3\n1.109140e+14\n0.024628\n0.035262\n0.001243\n0.0\n0.214152\n\n\n4\nMLP_Price_4\n1.314559e+14\n0.029189\n0.040948\n0.001677\n0.0\n0.248508\n\n\n5\nMLP_Price_5\n1.293315e+14\n0.028717\n0.041125\n0.001691\n0.0\n0.180185\n\n\n6\nMLP_Price_6\n6.711894e+13\n0.014903\n0.026100\n0.000681\n0.0\n0.008449\n\n\n7\nMLP_Price_7\n6.612054e+13\n0.014682\n0.020149\n0.000406\n0.0\n0.416803\n\n\n8\nMLP_Price_8\n4.960191e+13\n0.011014\n0.017467\n0.000305\n0.0\n0.047961\n\n\n9\nMLP_Price_9\n2.180156e+14\n0.048409\n0.075491\n0.005699\n0.0\n0.111378\n\n\n10\nMLP_Price_10\n1.742931e+14\n0.038701\n0.052252\n0.002730\n0.0\n0.267459\n\n\n11\nMLP_Price_11\n1.311039e+14\n0.029111\n0.041407\n0.001715\n0.0\n0.247492",
    "crumbs": [
      "Modelos de deep learning"
    ]
  }
]