---
title: "Modelos de deep learning"
---

# Importar librerías 

``` {python}
import pandas as pd
import numpy as np
import pickle

import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Dense, Input, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers, losses
from scikeras.wrappers import KerasRegressor

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score

from scipy.stats import jarque_bera
from statsmodels.stats.diagnostic import acorr_ljungbox

import warnings

import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings("ignore", category=UserWarning, module="scikeras.wrappers")
warnings.filterwarnings("ignore", category=UserWarning, module="keras.layers.core.dense")
```

# Importar datos

``` {python}
btc = pd.read_csv('data/btc_models.csv')

btc
```

``` {python}
btc.info()
```

``` {python}
btc = btc.fillna(0)

btc['Date'] = pd.to_datetime(btc['Date'], format='%Y-%m-%d')

btc.info()
```

# Obtención de las series de tiempo y conjuntos de prueba, validación y entrenamiento

``` {python}
def split_dataset(df: pd.DataFrame, tau: int, column: str) -> list:
    df[column] = df[column].fillna(0)

    serie = df[column]
    n = len(serie)
    train_w = n - (tau * 3)
    
    X_train = np.array([serie.iloc[i - tau:i].values.flatten() for i in range(tau, train_w)])
    y_train = np.array(serie.iloc[tau:train_w].values.flatten()).reshape(-1, 1)

    X_val = np.array([serie.iloc[i - tau:i].values.flatten() for i in range(train_w, train_w + tau)])
    y_val = np.array(serie.iloc[train_w:train_w + tau].values.flatten().tolist())

    X_test = np.array([serie.iloc[i - tau:i].values.flatten() for i in range(train_w + tau, train_w + (2 * tau))])
    y_test = np.array(serie.iloc[train_w + tau:train_w + (2 * tau)].values.flatten().tolist())

    return [X_train, y_train, X_val, y_val, X_test, y_test]
```

## Series de tiempo del precio

``` {python}
price_7 = split_dataset(btc, 7, 'Price')
price_14 = split_dataset(btc, 14, 'Price')
price_21 = split_dataset(btc, 21, 'Price')
price_28 = split_dataset(btc, 28, 'Price')

price = [price_7, price_14, price_21, price_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {price_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {price_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {price_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {price_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {price_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {price_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {price_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {price_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {price_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {price_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {price_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {price_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {price_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {price_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {price_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {price_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {price_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {price_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {price_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {price_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {price_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {price_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {price_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {price_28[5].shape}')
```

## Series de tiempo del retorno acumulado
``` {python}
at_7 = split_dataset(btc, 7, 'A_t')
at_14 = split_dataset(btc, 14, 'A_t')
at_21 = split_dataset(btc, 21, 'A_t')
at_28 = split_dataset(btc, 28, 'A_t')

at = [at_7, at_14, at_21, at_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {at_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {at_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {at_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {at_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {at_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {at_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {at_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {at_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {at_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {at_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {at_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {at_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {at_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {at_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {at_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {at_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {at_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {at_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {at_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {at_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {at_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {at_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {at_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {at_28[5].shape}')
```

## Series de tiempo de la volatilidad

### Serie de tiempo de la volatidad para σ = 7
``` {python}
vol_7 = split_dataset(btc, 7, 'σ_7')
vol_14 = split_dataset(btc, 14, 'σ_7')
vol_21 = split_dataset(btc, 21, 'σ_7')
vol_28 = split_dataset(btc, 28, 'σ_7')

vo_7 = [vol_7, vol_14, vol_21, vol_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')
```

### Serie de tiempo de la volatidad para σ = 14
``` {python}
vol_7 = split_dataset(btc, 7, 'σ_14')
vol_14 = split_dataset(btc, 14, 'σ_14')
vol_21 = split_dataset(btc, 21, 'σ_14')
vol_28 = split_dataset(btc, 28, 'σ_14')

vo_14 = [vol_7, vol_14, vol_21, vol_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')
```

### Serie de tiempo de la volatidad para σ = 21
``` {python}
vol_7 = split_dataset(btc, 7, 'σ_21')
vol_14 = split_dataset(btc, 14, 'σ_21')
vol_21 = split_dataset(btc, 21, 'σ_21')
vol_28 = split_dataset(btc, 28, 'σ_21')

vo_21 = [vol_7, vol_14, vol_21, vol_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')
```

### Serie de tiempo de la volatidad para σ = 28
``` {python}
vol_7 = split_dataset(btc, 7, 'σ_7')
vol_14 = split_dataset(btc, 14, 'σ_7')
vol_21 = split_dataset(btc, 21, 'σ_7')
vol_28 = split_dataset(btc, 28, 'σ_7')

vo_28 = [vol_7, vol_14, vol_21, vol_28]

print('τ = 7')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en X: {vol_7[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 7 en y: {vol_7[1].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en X: {vol_7[2].shape}')
print(f'Tamaño del conjunto de validación τ = 7 en y: {vol_7[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en X: {vol_7[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 7 en y: {vol_7[5].shape}')

print('\nτ = 14')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en X: {vol_14[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 14 en y: {vol_14[1].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en X: {vol_14[2].shape}')
print(f'Tamaño del conjunto de validación τ = 14 en y: {vol_14[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en X: {vol_14[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 14 en y: {vol_14[5].shape}')

print('\nτ = 21')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en X: {vol_21[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 21 en y: {vol_21[1].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en X: {vol_21[2].shape}')
print(f'Tamaño del conjunto de validación τ = 21 en y: {vol_21[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en X: {vol_21[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 21 en y: {vol_21[5].shape}')

print('\nτ = 28')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en X: {vol_28[0].shape}')
print(f'Tamaño del conjunto de entrenamiento τ = 28 en y: {vol_28[1].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en X: {vol_28[2].shape}')
print(f'Tamaño del conjunto de validación τ = 28 en y: {vol_28[3].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en X: {vol_28[4].shape}')
print(f'Tamaño del conjunto de prueba τ = 28 en y: {vol_28[5].shape}')
```

# Visualización de los pliegues extraídos

``` {python}
def plot_folds(data: np.array, tau_v: list, name: str):
    fig = go.Figure()

    colors = {
        'train': '#9B7EBD',
        'validation': '#7AB2D3',
        'test': '#CBD2A4'
    }

    for i, tau in enumerate(tau_v):
        X_train_s, y_train_s = data[i][0].shape, data[i][1].shape
        X_val_s, y_val_s = data[i][2].shape, data[i][3].shape
        X_test_s, y_test_s = data[i][4].shape, data[i][5].shape

        fig.add_trace(go.Scatter(
            x=list(range(1, X_train_s[0] + 1)),
            y=[i + 1] * X_train_s[0],
            mode='lines',
            line=dict(color=colors['train'], width=6),
            name='Train' if i == 0 else "",
            showlegend=(i == 0)
        ))

        fig.add_trace(go.Scatter(
            x=list(range(X_train_s[0] + 1, X_train_s[0] + X_val_s[0] + 1)),
            y=[i + 1] * X_val_s[0],
            mode='lines',
            line=dict(color=colors['validation'], width=6),
            name='Validation' if i == 0 else "",
            showlegend=(i == 0)
        ))

        fig.add_trace(go.Scatter(
            x=list(range(X_train_s[0] + X_val_s[0] + 1, X_train_s[0] + X_val_s[0] + X_test_s[0] + 1)),
            y=[i + 1] * X_test_s[0],
            mode='lines',
            line=dict(color=colors['test'], width=6),
            name='Test' if i == 0 else "",
            showlegend=(i == 0)
        ))

    fig.update_layout(
        title=f"Visualización de pliegues para {name}",
        xaxis_title="Índice de tiempo",
        yaxis_title="Número de pliegue",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin={'b': 0, 'r': 30, 'l': 30, 't': 80},
        plot_bgcolor='rgba(0, 0, 0, 0.0)',
        paper_bgcolor='rgba(0, 0, 0, 0.0)',
        font_color="white",
        hoverlabel=dict(
            bgcolor="#222"
        ),
        xaxis=dict(gridcolor='#222', tickfont=dict(color='white'), range = [4800, 5000]),
        yaxis=dict(gridcolor='#222', tickfont=dict(color='white'), tickvals=[1, 2, 3, 4])
    )

    return fig
```

## Pliegues del precio

``` {python}
#| output: false
tau_v = [7, 14, 21, 28]

fig_p = plot_folds(price, tau_v, 'Price')
fig_p.show()
```

``` {python}
#| echo: false
fig_p.write_html('graphs/price_folds.html')
```

``` {=html}
<iframe
    src = 'graphs/price_folds.html'
    width = '730'
    height = '400'
    title = 'Visualización de los folds para la variable del precio'
>
</iframe>
```

## Pliegues del retorno acumulado

``` {python}
#| output: false
fig_p = plot_folds(price, tau_v, 'A_j')
fig_p.show()
```

``` {python}
#| echo: false
fig_p.write_html('graphs/returncumsum_folds.html')
```

``` {=html}
<iframe
    src = 'graphs/returncumsum_folds.html'
    width = '730'
    height = '400'
    title = 'Visualización de los folds para la variable del retorno acumulado'
>
</iframe>
```

# Modelos de Deep Learning

## Multilayer Perceptron Models (MLP)

### Predicciones para el precio

#### τ = 7

``` {python}
def build_mlp(dim, learning_rate=0.001, activation='relu'):
    model = Sequential()
    model.add(Input(shape=(dim,)))
    model.add(Dense(64, activation=activation))
    model.add(Dense(32, activation=activation))
    model.add(Dense(1, activation='linear'))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=losses.MeanSquaredError())
    return model
```

``` {python}
def get_grid(data, dim, var, tau, w = 1):
    if var == 'volatilidad':
        folder_path = f'best_grids/{var}/{var}_{w}_{tau}.pkl'
    else:
        folder_path = f'best_grids/{var}/{var}_{tau}.pkl'

    if os.path.exists(folder_path):
        print("Cargando resultados guardados...")
        with open(folder_path, 'rb') as file:
            results = pickle.load(file)
        return results

    model = KerasRegressor(build_fn = build_mlp, verbose = 0, dim = dim)

    param = {
        'model__learning_rate': [0.001, 0.01, 0.1, 0.2],
        'model__activation': ['relu', 'tanh', 'sigmoid'],
        'epochs': [50, 100, 150]
    }

    grid = GridSearchCV(
        estimator = model,
        param_grid = param,
        cv = 3,
        verbose = 2
    )

    results = grid.fit(data[0], data[1])

    with open(folder_path, 'wb') as file:
        pickle.dump(results, file)

    return results
```

``` {python}
dim = price[0][0].shape[1]

results = get_grid(price[0], dim, 'price', 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
def load_models(type_, folder, w, n = 1):
    if folder == 'volatilidad':
        folder_path = f'models/{type_}/{folder}/{n}/{w}'
    else:
        folder_path = f'models/{type_}/{folder}/{w}'

    models = []
    for filename in sorted(os.listdir(folder_path)):
        if filename.endswith('.keras'):
            models.append(load_model(os.path.join(folder_path, filename)))
    return models

def save_models(models, type_, folder, w, n = 1):
    if folder == 'volatilidad':
        folder_path = f'models/{type_}/{folder}/{n}/{w}'
    else:
        folder_path = f'models/{type_}/{folder}/{w}'

    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
    
    for i, model in enumerate(models):
        model.save(os.path.join(folder_path, f'MLP_{w}_{i}.keras'))

def build_model(type_, var, dim, neurons, dropouts, activation, learning_rate, w, n = 1):
    models = load_models(type_, var, w, n)
    if models:
        print(f"Modelos cargados desde la carpeta '{var}'.")
        return models

    print(f"No se encontraron modelos en la carpeta '{var}', construyendo nuevos modelos...")

    models = []

    for neuron in neurons:
        for dropout in dropouts:
            model = Sequential()
            model.add(Input(shape = (dim, )))
            model.add(Dense(neuron, activation=activation))
            model.add(Dense(neuron // 2, activation=activation))
            model.add(Dense(neuron // 2, activation=activation))
            model.add(Dropout(dropout))
            model.add(Dense(1, activation='linear'))
            model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
            
            models.append(model)

            print(f'Modelo con {(neuron, neuron // 2, neuron // 2, 1)} neuronas y dropout {dropout}:')
            model.summary()

    save_models(models, type_, var, w, n)
    return models
``` 
``` {python}
neurons = [32, 64, 128]
dropouts = [0.2, 0.4, 0.6, 0.8]

models = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 7)
```

``` {python}
def best_model(models, X_val, y_val):
    results = []

    for i, model in enumerate(models):
        pred = model.predict(X_val)

        pred = pred.ravel()
        y_val = y_val.ravel()

        mape = mean_absolute_percentage_error(y_val, pred)
        mae = mean_absolute_error(y_val, pred)
        mse = mean_squared_error(y_val, pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_val, pred)

        #ljungbox = acorr_ljungbox(pred - y_val, lags = [10], return_df = True)['lb_pvalue'].iloc[0]
        jb_stat, jb_p = jarque_bera(pred - y_val)

        print(f'Modelo {i}: MSE = {mse:.4f}')

        results.append({
            "Model Name": f'MLP_Price_{i}',
            "MAPE": mape,
            "MAE": mae,
            "RMSE": rmse,
            "MSE": mse,
            "R2": r2,
            #"Ljung-Box P-Value": ljungbox,
            "Jarque-Bera P-Value": jb_p
        })

    results = pd.DataFrame(results)
    return results
```

``` {python}
mlp_p7_metrics = best_model(models, price[0][2], price[0][3])

mlp_p7_metrics
```

#### τ = 14

``` {python}
dim = price[1][0].shape[1]

results = get_grid(price[1], dim, 'price', 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 14)

mlp_p14_metrics = best_model(models, price[1][2], price[1][3])
mlp_p14_metrics
```

#### τ = 21

``` {python}
dim = price[2][0].shape[1]

results = get_grid(price[2], dim, 'price', 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 21)

mlp_p21_metrics = best_model(models, price[2][2], price[2][3])
mlp_p21_metrics
```

#### τ = 28

``` {python}
dim = price[3][0].shape[1]

results = get_grid(price[3], dim, 'price', 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'price', dim, neurons, dropouts, best_activation, best_mu, 28)

mlp_p28_metrics = best_model(models, price[3][2], price[3][3])
mlp_p28_metrics
```

### Predicciones para el retorno acumulado

#### τ = 7

``` {python}
dim = at[0][0].shape[1]

results = get_grid(at[0], dim, 'retorno', 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 7)

mlp_at7_metrics = best_model(models, at[0][2], at[0][3])
mlp_at7_metrics
```

#### τ = 14

``` {python}
dim = at[1][0].shape[1]

results = get_grid(at[1], dim, 'retorno', 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 14)

mlp_at14_metrics = best_model(models, at[1][2], at[1][3])
mlp_at14_metrics
```

#### τ = 21

``` {python}
dim = at[2][0].shape[1]

results = get_grid(at[2], dim, 'retorno', 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 21)

mlp_at21_metrics = best_model(models, at[2][2], at[2][3])
mlp_at21_metrics
```

#### τ = 28

``` {python}
dim = at[3][0].shape[1]

results = get_grid(at[3], dim, 'retorno', 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'retorno', dim, neurons, dropouts, best_activation, best_mu, 28)

mlp_at28_metrics = best_model(models, at[3][2], at[3][3])
mlp_at28_metrics
```

### Predicciones para la volatilidad

#### Volatilidad con ventana σ = 7 

##### τ = 7

``` {python}
dim = vo_7[0][0].shape[1]

results = get_grid(vo_7[0], dim, 'volatilidad', 7, 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 7)

mlp_vol7_7_metrics = best_model(models, vo_7[0][2], vo_7[0][3])
mlp_vol7_7_metrics
```

##### τ = 14

``` {python}
dim = vo_7[1][0].shape[1]

results = get_grid(vo_7[1], dim, 'volatilidad', 14, 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 7)

mlp_vol7_14_metrics = best_model(models, vo_7[1][2], vo_7[1][3])
mlp_vol7_14_metrics
```

##### τ = 21

``` {python}
dim = vo_7[2][0].shape[1]

results = get_grid(vo_7[2], dim, 'volatilidad', 21, 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 7)

mlp_vol7_21_metrics = best_model(models, vo_7[2][2], vo_7[2][3])
mlp_vol7_21_metrics
```

##### τ = 28

``` {python}
dim = vo_7[3][0].shape[1]

results = get_grid(vo_7[3], dim, 'volatilidad', 28, 7)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 7)

mlp_vol7_28_metrics = best_model(models, vo_7[3][2], vo_7[3][3])
mlp_vol7_28_metrics
```

#### Volatilidad con ventana σ = 14

##### τ = 7

``` {python}
dim = vo_14[0][0].shape[1]

results = get_grid(vo_14[0], dim, 'volatilidad', 7, 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 14)

mlp_vol14_7_metrics = best_model(models, vo_14[0][2], vo_14[0][3])
mlp_vol14_7_metrics
```

##### τ = 14

``` {python}
dim = vo_14[1][0].shape[1]

results = get_grid(vo_14[1], dim, 'volatilidad', 14, 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 14)

mlp_vol14_14_metrics = best_model(models, vo_14[1][2], vo_14[1][3])
mlp_vol14_14_metrics
```

##### τ = 21

``` {python}
dim = vo_14[2][0].shape[1]

results = get_grid(vo_14[2], dim, 'volatilidad', 21, 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 14)

mlp_vol14_21_metrics = best_model(models, vo_14[2][2], vo_14[2][3])
mlp_vol14_21_metrics
```

##### τ = 28

``` {python}
dim = vo_14[3][0].shape[1]

results = get_grid(vo_14[3], dim, 'volatilidad', 28, 14)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 14)

mlp_vol14_28_metrics = best_model(models, vo_14[3][2], vo_14[3][3])
mlp_vol14_28_metrics
```

#### Volatilidad con ventana σ = 21

##### τ = 7

``` {python}
dim = vo_21[0][0].shape[1]

results = get_grid(vo_21[0], dim, 'volatilidad', 7, 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 21)

mlp_vol21_7_metrics = best_model(models, vo_21[0][2], vo_21[0][3])
mlp_vol21_7_metrics
```

##### τ = 14

``` {python}
dim = vo_21[1][0].shape[1]

results = get_grid(vo_21[1], dim, 'volatilidad', 14, 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 21)

mlp_vol21_14_metrics = best_model(models, vo_21[1][2], vo_21[1][3])
mlp_vol21_14_metrics
```

##### τ = 21

``` {python}
dim = vo_21[2][0].shape[1]

results = get_grid(vo_21[2], dim, 'volatilidad', 21, 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 21)

mlp_vol21_21_metrics = best_model(models, vo_21[2][2], vo_21[2][3])
mlp_vol21_21_metrics
```

##### τ = 28

``` {python}
dim = vo_21[3][0].shape[1]

results = get_grid(vo_21[3], dim, 'volatilidad', 28, 21)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 21)

mlp_vol21_28_metrics = best_model(models, vo_21[3][2], vo_21[3][3])
mlp_vol21_28_metrics
```

#### Volatilidad con ventana σ = 28

##### τ = 7

``` {python}
dim = vo_28[0][0].shape[1]

results = get_grid(vo_28[0], dim, 'volatilidad', 7, 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 7, 28)

mlp_vol28_7_metrics = best_model(models, vo_28[0][2], vo_28[0][3])
mlp_vol28_7_metrics
```

##### τ = 14

``` {python}
dim = vo_28[1][0].shape[1]

results = get_grid(vo_28[1], dim, 'volatilidad', 14, 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 14, 28)

mlp_vol28_14_metrics = best_model(models, vo_28[1][2], vo_28[1][3])
mlp_vol28_14_metrics
```

##### τ = 21

``` {python}
dim = vo_28[2][0].shape[1]

results = get_grid(vo_28[2], dim, 'volatilidad', 21, 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 21, 28)

mlp_vol28_21_metrics = best_model(models, vo_28[2][2], vo_28[2][3])
mlp_vol28_21_metrics
```

##### τ = 28

``` {python}
dim = vo_28[3][0].shape[1]

results = get_grid(vo_28[3], dim, 'volatilidad', 28, 28)

best_params = results.best_params_
best_activation = results.best_params_['model__activation']
best_epochs = results.best_params_['epochs']
best_mu = results.best_params_['model__learning_rate']
best_score = results.best_score_

print(f"Mejor función de activación: {best_activation}")
print(f"Mejor número de epocas: {best_epochs}")
print(f"Mejor Longitud de paso μ (Learning Rate): {best_mu}")
print(f"Mejor Puntuación: {best_score}")
```

``` {python}
models = build_model('MLP', 'volatilidad', dim, neurons, dropouts, best_activation, best_mu, 28, 28)

mlp_vol28_28_metrics = best_model(models, vo_28[3][2], vo_28[3][3])
mlp_vol28_28_metrics
```